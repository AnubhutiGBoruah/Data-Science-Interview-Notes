{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkahjcKYCnVCUeLmcZAMwG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnubhutiGBoruah/Data-Science-Interview-Notes/blob/main/Introduction_to_Statistical_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **What is Statistical Learning?**"
      ],
      "metadata": {
        "id": "kOnnkb_1ocF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example:** Suppose that we are statistical consultants hired by a client to investigate the association between advertising and sales of a particular product. The Advertising data set consists of the sales of that product in 200 different markets, along with advertising budgets for the product in each of those markets for three different media: TV, radio, and newspaper.\n",
        "\n",
        "**Goal:** It is not possible for our client to directly increase sales of the product. On the other hand, they can control the advertising expenditure in each of the three media.if we determine that there is an association between advertising and sales, then we can instruct our client to adjust advertising budgets, thereby indirectly increasing sales. In other words, our goal is to develop an accurate model that can be used to predict sales on the basis of the three media budgets.\n",
        "\n",
        "**Important Variables:**\n",
        "\n",
        "*   Input Variables/Predictors/Independent Variables:the advertising budgets\n",
        "*   output variables/Features/dependent Variables:sales\n",
        "\n",
        "\n",
        "\n",
        "More generally, suppose that we observe a quantitative response $Y$ and $p$ different predictors, $X_1 $, $X_2$, . . . , $X_p$ . We assume that there is some relationship between $Y$ and $X = (X_1,X_2,...,X_p)$, which can be written in the very general form\n",
        "\\begin{equation}\n",
        "Y =f(X)+ε.\n",
        "\\end{equation}\n",
        "\n",
        "Here $f$ is some fixed but unknown function of $X_1$, . . . , $X_p$, and ε is a random error term, which is independent of X and has mean zero. In this formulation, $f$ represents the systematic information that $X$ provides about $Y$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y__vx8gHiaWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Why Estimate $f$?**"
      ],
      "metadata": {
        "id": "pAL3SCI7F8XA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In essence, statistical learning refers to a set of approaches for estimating $f$."
      ],
      "metadata": {
        "id": "CxXl9bhnzzXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "There are two main reasons that we may wish to estimate $f$:\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*   Prediction:\n",
        "\n",
        "In many situations, a set of inputs X are readily available, but the output Y cannot be easily obtained.\n",
        "We  can predict Y using\n",
        "\\begin{equation}\n",
        "Y = \\tilde{f(X)}\n",
        "\\end{equation}\n",
        "where $\\tilde{f}$ represents our estimate for $f$ , and $\\tilde{Y}$ represents the resulting pre- diction for Y . In this setting, $\\tilde{f}$ is often treated as a black box, in the sense that one is not typically concerned with the exact form of $f$, provided that it yields accurate predictions for $Y$ .\n",
        "\n",
        "\n",
        "As an example, suppose that $X_1, . . . , X_p$ are characteristics of a patient’s blood sample that can be easily measured in a lab, and $Y $ is a variable encoding the patient’s risk for a severe adverse reaction to a particular drug. It is natural to seek to predict $Y $ using $X$, since we can then avoid giving the drug in question to patients who are at high risk of an adverse reaction—that is, patients for whom the estimate of $Y $ is high.\n",
        "\n",
        "\n",
        "\n",
        "The accuracy of $\\tilde{Y} $ as a prediction for $Y $ depends on two quantities,\n",
        "\n",
        "\n",
        "* ** Reducible error :**   \n",
        "In general, $ \\tilde{f }$  will not be a perfect estimate for $ \\tilde{f } $ , and this inaccuracy will introduce some error. This error is reducible because we can potentially improve the accuracy of $\\tilde{f }$ by using the most appropriate statistical learning technique to estimate $f$.\n",
        "*   Irreducible error:\n",
        " our prediction would still have some error in it,even if we manage to save  This is because $Y$ is also a function of $\\epsilon$ , which, by definition, cannot be predicted using $X$. Therefore, variability associated with \\epsilon  also affects the accuracy of our predictions.The quantity $\\epsilon$  may con- tain unmeasured variables that are useful in predicting $Y$  : since we don’t measure them, $f$ cannot use them for its prediction. The quantity $\\epsilon$  may also contain unmeasurable variation. For example, the risk of an adverse reaction might vary for a given patient on a given day, depending on manufacturing variation in the drug itself or the patient’s general feeling of well-being on that day.\n",
        "\n",
        "\n",
        "The focus should be  on techniques for estimating $f$ with the aim of minimizing the reducible error. It is important to keep in mind that the irreducible error will always provide an upper bound on the accuracy of our prediction for $Y$ . This bound is almost always unknown in practice.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        " * **Inference:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " We are often interested in understanding the association between $Y$ and $X_1$,...,$X_p$. In this situation we wish to estimate $f$, but our goal is not necessarily to make predictions for $Y$. Now $\\tilde{f} cannot be treated as a black box, because we need to know its exact form. In this setting, one may be interested in answering the following questions:\n",
        "\n",
        "\n",
        " • Which predictors are associated with the response?\n",
        "\n",
        "\n",
        "\n",
        ">   It is often the case that only a small fraction of the available predictors are substantially associated with Y . Identifying the few important predictors among a large set of possible variables can be extremely useful, depending on the application.\n",
        "\n",
        "\n",
        "*  What is the relationship between the response and each predictor?\n",
        "\n",
        "> Some predictors may have a positive relationship with Y , in the sense that larger values of the predictor are associated with larger values of Y . Other predictors may have the opposite relationship. Depending on the complexity of f, the relationship between the response and a given predictor may also depend on the values of the other predictors.\n",
        "\n",
        "*  Can the relationship between Y and each predictor be adequately summarized using a linear equation, or is the relationship more complicated?\n",
        "\n",
        ">Historically, most methods for estimating f have taken a linear form. In some situations, such an assumption is reasonable or even desirable. But often the true relationship is more complicated, in which case a linear model may not provide an accurate representation of the relationship between the input and output variables.\n",
        "\n",
        "\n",
        "\n",
        "Let us take the example in the beggining .It falls into the inference paradigm.\n",
        "\n",
        "\n",
        "\n",
        " One may be interested in answering questions such as:\n",
        " Which media generate the biggest boost in sales? or\n",
        "  How large of an increase in sales is associated with a given increase in TV advertising?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Another example involves modeling the brand of a product that a customer might purchase based on variables such as price, store location, discount levels, competition price, and so forth. In this situation one might really be most interested in the association between each variable and the probability of purchase. For instance, to what extent is the product’s price associated with sales? This is an example of modeling for inference.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Finally, some modeling could be conducted both for prediction and inference. For example, in a real estate setting, one may seek to relate values of homes to inputs such as crime rate, zoning, distance from a river, air quality, schools, income level of community, size of houses, and so forth. In this case one might be interested in the association between each individual input variable and housing price—for instance, how much extra will a house be worth if it has a view of the river? This is an inference problem. Alternatively, one may simply be interested in predicting the value of a home given its characteristics: is this house under- or over-valued? This is a prediction problem.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W4ORf3-Kzgls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How Do We Estimate $f$?\n",
        "\n"
      ],
      "metadata": {
        "id": "IadsaDpLyuzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have observed a set of n different data points. These observations are called the training data because we will use these observations to train, or teach, our method how to estimate $f$. Let $x_{ij}$ represent the value of the $j^{th}$ predictor, or input, for observation $i$, where $i = 1,2,...,n$ and $j = 1,2,...,p$. Correspondingly, let $y_i$ represent the response variable for the $i_th$ observation. Then our training data consist of ${(x_1,y_1),(x_2,y_2),...,(x_n,y_n)}$.\n",
        "\n",
        "Our goal is to apply a statistical learning method to the training data in order to estimate the unknown function $f$.\n",
        "\n",
        "\n",
        "Broadly speaking, most statistical learning methods for this task can be character- ized as either parametric or non-parametric. We now briefly discuss these two types of approach"
      ],
      "metadata": {
        "id": "-HVxjSPkzEbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parametric Methods\n",
        "\n",
        "Parametric methods involve a two-step model-based approach.\n",
        "\n",
        "\n",
        "1.   First, we make an assumption about the functional form, or shape, of $ f$. For example, one very simple assumption is that $ f$ is linear in\n",
        "linear model\n",
        "\\begin{equation}\n",
        "f(X)=β_0 +β_1X_1 +β_2X_2 +···+β_pX_p\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "This is a linear model,  Once we have assumed that f is linear, the problem of estimat-ing f is greatly simplified. Instead of having to estimate an entirely arbitrary p-dimensional function $f(X)$, one only needs to estimate the $p+1 $ coefficients $β_0,β_1,...,β_p$.\n",
        "\n",
        "\n",
        "2.  After a model has been selected, we need a procedure that uses the training data to fit or train the model. In the case of the linear mode we need to estimate the parameters $β_0,β_1,...,β_p$.\n",
        "\n",
        "The most common approach to fitting the model is referred to as (ordinary) least squares,\n",
        "\n",
        "\n",
        "The model-based approach just described is referred to as parametric; it reduces the problem of estimating f down to one of estimating a set of parameters. Assuming a parametric form for $f$ simplifies the problem of estimating $f$ because it is generally much easier to estimate a set of pa- rameters, such as $β_0,β_1,...,β_p$ in the linear model , than it is to fit an entirely arbitrary function f.\n",
        "\n",
        " The potential disadvantage of a parametric approach is that the model we choose will usually not match the true unknown form of f. If the chosen model is too far from the true f, then our estimate will be poor.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HSEI6-QA4ts7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Non-Parametric Methods**\n",
        "\n",
        "\n",
        "\n",
        "Building non-parametric models do not make explicit assumptions about the functional form such as a linear model in the case of parametric models.\n",
        "\n",
        "**Instead, non-parametric models can be seen as the function approximation that gets as close to the data points as possible**. Non-parametric models do not rely on predefined parameter settings, enabling them to adapt to complex and irregular patterns within the data.\n",
        "\n",
        "\n",
        " The advantage over parametric approaches is that by avoiding the assumption of a particular functional form such as a linear model, non-parametric models have the potential to accurately fit a wider range of possible shapes for the actual or true function. Any parametric approach brings with it the possibility that the functional form (linear model) which is very different from the true function, in which case the resulting model will not fit the data well.\n",
        "\n",
        " Examples of non-parametric models include fully non-linear algorithms such as bagging, boosting, support vector machines, decision trees, random forests, etc.\n",
        "\n",
        "\n",
        "But non-parametric approaches do suffer from a major disadvantage: since they do not reduce the problem of estimating $f$ to a small number of parameters, a very large number of observations (far more than is typically needed for a parametric approach) is required in order to obtain an accurate estimate for $f$ .\n"
      ],
      "metadata": {
        "id": "aOIQAO9E64mo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Trade-Off Between Prediction Accuracy and Model Interpretability\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U-kVxmhJ9wDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of the many methods that we study, some are less flexible, or more restrictive, in the sense that they can produce just a relatively small range of shapes to estimate f. For example, linear regression is a relatively inflexible approach, because it can only generate linear functions such as the lines or the plane . Other methods, such as the thin plate splines, are considerably more flexible because they can generate a much wider range of possible shapes to estimate $f$.\n",
        "\n",
        "One might reasonably ask the following question: why would we ever choose to use a more restrictive method instead of a very flexible approach? There are several reasons that we might prefer a more restrictive model. If we are mainly interested in inference, then restrictive models are much more interpretable. For instance, when inference is the goal, the linear model may be a good choice since it will be quite easy to understand the relationship between $Y$ and $X_1$,$X_2,...,X_p$. In contrast, very flexible approaches, such as the splines , and the boosting methods  can lead to such complicated estimates of f that it is difficult to understand how any individual predictor is associated with the response.\n",
        "\n",
        "We have established that when inference is the goal, there are clear advantages to using simple and relatively inflexible statistical learning methods. In some settings, however, we are only interested in prediction, and the interpretability of the predictive model is simply not of interest. For instance, if we seek to develop an algorithm to predict the price of a stock, our sole requirement for the algorithm is that it predict accurately— interpretability is not a concern. In this setting, we might expect that it will be best to use the most flexible model available. Surprisingly, this is not always the case! We will often obtain more accurate predictions using a less flexible method. This phenomenon, which may seem counterintu- itive at first glance, has to do with the potential for overfitting in highly flexible methods.\n"
      ],
      "metadata": {
        "id": "b3zqCXZ9AssV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Supervised Versus Unsupervised Learning\n"
      ],
      "metadata": {
        "id": "B91SgKRPCGGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most statistical learning problems fall into one of two categories:supervised or unsupervised.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The examples that we have discussed so far in this chapter all fall into the supervised learning domain. For each observation of the predictor measurement(s) $x_i$, $i = 1, . . . , n$ there is an associated response measurement $y_i$. We wish to fit a model that relates the response to the predictors, with the aim of accurately predicting the response for future observations (prediction) or better understanding the relationship between the response and the predictors (inference). Many classical statistical learn- ingmethodssuchaslinearregressionandlogisticregression(Chapter4),as well as more modern approaches such as GAM, boosting, and support vec- tor machines, operate in the supervised learning domain.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "By contrast, unsupervised learning describes the somewhat more challenging situation in which for every observation $i = 1,...,n$, we observe a vector of measurements $x_i$ but no associated response $y_i$. It is not possible to fit a linear regression model, since there is no response variable to predict. In this setting, we are in some sense working blind; the situation is referred to as unsupervised because we lack a response variable that can supervise our analysis. What sort of statistical analysis is possible? We can seek to understand the relationships between the variables or between the observations. One statistical learning tool that we may use in this setting is cluster analysis, or clustering. The goal of cluster analysis is to ascertain,on the basis of $x_1,...,x_n$,whether the observations fall into relatively distinct groups.\n",
        "\n",
        "For example, in a market segmentation study we might observe multiple characteristics (variables) for potential customers, such as zip code, family income, and shopping habits. We might believe that the customers fall into different groups, such as big spenders versus low spenders. If the information about each customer’s spending patterns were available, then a supervised analysis would be possible. However, this information is not available—that is, we do not know whether each potential customer is a big spender or not. In this setting, we can try to cluster the customers on the basis of the variables measured, in order to identify whether they are big or small spenders.\n",
        "\n",
        "\n",
        "\n",
        "The main differences of supervised vs unsupervised learning include:\n",
        "\n",
        "\n",
        "\n",
        "1.  The need for labelled data in supervised machine learning.\n",
        "2.  The problem the model is deployed to solve. Supervised machine learning   \n",
        "    is  generally used to classify data or make predictions, whereas unsupervised learning is generally used to understand relationships within datasets.\n",
        "3.  Supervised machine learning is much more resource-intensive because of     \n",
        "    the need for labelled data.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MVAmVxBZCxUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification versus Regression"
      ],
      "metadata": {
        "id": "VRysNR20Hr35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most significant difference between regression vs classification is that while regression helps predict a continuous quantity, classification predicts discrete class labels.\n",
        "\n",
        "Let’s consider a dataset that contains student information of a particular university. A regression algorithm can be used in this case to predict the height of any student based on their weight, gender, diet, or subject major. We use regression in this case because height is a continuous quantity. There is an infinite number of possible values for a person’s height.\n",
        "\n",
        "On the contrary, classification can be used to analyse whether an email is a spam or not spam. The algorithm checks the keywords in an email and the sender’s address is to find out the probability of the email being spam. Similarly, while a regression model can be used to predict temperature for the next day, we can use a classification algorithm to determine whether it will be cold or hot according to the given temperature values."
      ],
      "metadata": {
        "id": "9ST2K4iGE-aQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assessing Model Accuracy"
      ],
      "metadata": {
        "id": "uKHjtj4FQIfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Why is it necessary to introduce so many different statistical learning approaches, rather than just a single best method? There is no free lunch in statistics: no one method dominates all others over all possible data sets. On a particular data set, one specific method may work best, but some other method may work better on a similar but different data set. Hence it is an important task to decide for any given set of data which method produces the best results. Selecting the best approach can be one of the most challenging parts of performing statistical learning in practice.\n",
        "\n",
        "\n",
        " Prediction accuracy versus interpretability.\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "\n",
        "• Good fit versus over-fit or under-fit.\n",
        "— How do we know when the fit is just right?\n",
        "• Parsimony versus black-box.\n",
        "— We often prefer a simpler model involving fewer variables over a black-box predictor involving them all.\n"
      ],
      "metadata": {
        "id": "O8ducD1OQrjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Measuring the Quality of Fit"
      ],
      "metadata": {
        "id": "rbBwjWSZRP6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to evaluate the performance of a statistical learning method on a given data set, we need some way to measure how well its predictions actually match the observed data. That is, we need to quantify the extent to which the predicted response value for a given observation is close to the true response value for that observation.\n",
        "\n",
        "In the regression setting, the most commonly-used measure is the mean squared error (MSE), given by mean squared error .\n",
        "\n",
        "The MSE will be small if the predicted responses are very close to the true responses, and will be large if for some of the observations, the predicted and true responses differ substantially.\n",
        "\n",
        "The MSE  is computed using the training data that was used to fit the model, and so should more accurately be referred to as the training MSE. But in general, we do not really care how well the method works on the training data. Rather, we are interested in the accuracy of the predictions that we obtain when we apply our method to previously unseen test data.\n",
        "\n",
        "\n",
        "\n",
        "**Why is this what we care about?**\n",
        "\n",
        "Suppose that we are interested in developing an algorithm to predict a stock’s price based on previous stock returns. We can train the method using stock returns from the past 6 months. But we don’t really care how well our method predicts last week’s stock price. We instead care about how well it will predict tomorrow’s price or next month’s price.\n",
        "\n",
        "On a similar note, suppose that we have clinical measurements (e.g. weight, blood pressure, height, age, family history of disease) for a number of patients, as well as information about whether each patient has diabetes. We can use these patients to train a statistical learn- ing method to predict risk of diabetes based on clinical measurements. In practice, we want this method to accurately predict diabetes risk for future patients based on their clinical measurements. We are not very interested in whether or not the method accurately predicts diabetes risk for patients used to train the model, since we already know which of those patients have diabetes.\n",
        "\n",
        "**Goal:**\n",
        "\n",
        "We want to choose the method that gives the lowest test MSE,as opposed to the lowest training MSE.\n",
        "\n",
        "\n",
        "We’d like to select the model for which this quantity is as small as possible. How can we go about trying to select a method that minimizes the test MSE? In some settings, we may have a test data set available—that is, we may have access to a set of observations that were not used to train the statistical learning method. We can then simply evaluate MSE on the test observations, and select the learning method for which the test MSE is smallest. But what if no test observations are available? In that case, one might imagine simply selecting a statistical learning method that minimizes the training MSE . This seems like it might be a sensible approach, since the training MSE and the test MSE appear to be closely related. Unfortunately, there is a fundamental problem with this strategy: there is no guarantee that the method with the lowest training MSE will also have the lowest test MSE. Roughly speaking, the problem is that many statistical methods specifically estimate coefficients so as to minimize the training set MSE. For these methods, the training set MSE can be quite\n",
        "small, but the test MSE is often much larger.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V8TpRq2MRZ7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elucidating Bias, Variance, Under-fitting, and Over-fitting"
      ],
      "metadata": {
        "id": "3YpfX-AFe_NE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  **Degrees of freedom:**\n",
        "\n",
        "Roughly, the minimum amount of data\n",
        "needed to calculate a statistic. More practically, it is a number, or numbers, used to approximate the number of observations in the data set for the purpose of determining statistical significance.\n",
        "\n",
        "\n",
        "Degrees of freedom = number of independent values — number of statistics\n",
        "\n",
        "\n",
        "Most commonly used formula is:\n",
        "df=N-1\n",
        "\n",
        "For example :-\n",
        "If we have 100 independent samples and we want to calculate a statistic of the sample, like the mean. All 100 samples are used in the calculation and there is one statistic, so the number of degrees of freedom for the mean, in this case is calculated as:\n",
        "$d_f=N-1$\\\n",
        "$df=99$\n",
        "\n",
        "Degrees of Freedom in Machine Learning\n",
        "In predictive modeling, the degrees of freedom often refers to the number of parameters in the model that are estimated from data.\n",
        "\n",
        "Let’s learn it with the example of Linear Regression.\n",
        "Let’s consider a two variable linear regression.\n",
        "\\begin{equation}\n",
        "\\hat{y} = x_1 * beta_1 + x_2 * beta_2\n",
        "\\end{equation}\n",
        "\n",
        "This linear regression model has two degrees of freedom because there are two parameters in the model that must be estimated from a training dataset. Adding one more variable to the data would add one more degree of freedom for the model.\n",
        "\n",
        "\n",
        " As model flexibility increases, the training MSE will decrease, but the test MSE may not. When a given method yields a small training MSE but a large test MSE, we are said to be overfitting the data. This happens because our statistical learning procedure is working too hard to find patterns in the training data, and may be picking up some patterns that are just caused by random chance rather than by true properties of the unknown function $f$. When we overfit the training data, the test MSE will be very large because the supposed patterns that the method found in the training data simply don’t exist in the test data.\n",
        "\n",
        "  Note that regardless of whether or not overfitting has occurred, we almost always expect the training MSE to be smaller than the test MSE because most statistical learning methods either directly or indirectly seek to minimize the training MSE. Overfitting refers specifically to the case in which a less flexible model would have yielded a smaller test MSE.\n",
        "\n",
        "\n",
        "\n",
        " ** Overfitting**\n",
        "\n",
        "\n",
        "\n",
        "*  When a statistical model or machine learning         algorithm   captures the noise of the data which has high variance.\n",
        "* Intuitively, overfitting occurs when the model or the algorithm fits the data too well and hence low bias.\n",
        "*  Overfitting is often a result of an excessively complicated model,\n",
        "\n",
        "\n",
        "**Underfitting**\n",
        "\n",
        " * Underfitting is often a result of an excessively simple model.\n",
        " * occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data. Intuitively, underfitting occurs when the model or the algorithm does not fit the data well enough.\n",
        " * Specifically, underfitting occurs if the model or algorithm shows low variance but high bias.\n",
        "\n",
        "\n",
        "\n",
        "**Both overfitting and underfitting lead to poor predictions on new data sets.**\n",
        "\n",
        "**What is Bias?**\n",
        "\n",
        "Bias is the difference between the average prediction of our model and the correct value which we are trying to predict. A model with high bias pays very little attention to the training data and oversimplifies the model.\n",
        "\n",
        "\n",
        "\n",
        "**What is a Variance?**\n",
        "\n",
        "Variance is the variability of model prediction for a given data point or a value that tells us the spread of our data. A model with high variance pays a lot of attention to training data and does not generalize on the data which it hasn’t seen before.\n",
        "\n",
        "Variance refers to the amount by which $\\hat{f}$ would change if we estimated it using a different training data set. Since the training data are used to fit the statistical learning method, different training data sets\n",
        "will result in a different f. But ideally the estimate for f should not vary too much between training sets. However, if a method has high variance then small changes in the training data can result in large changes in f.\n",
        "\n",
        "\n",
        "\n",
        "As a general rule, as we use more flexible methods, the variance will increase and the bias will decrease. The relative rate of change of these two quantities determines whether the test MSE increases or decreases. As we increase the flexibility of a class of methods, the bias tends to initially decrease faster than the variance increases. Consequently, the expected test MSE declines. However, at some point increasing flexibility has little impact on the bias but starts to significantly increase the variance. When this happens the test MSE increases.\n",
        "\n",
        "\n",
        "Good test set performance of a statistical learning method requires low variance as well as low squared bias. This is referred to as a trade-off because it is easy to obtain a method with extremely low bias but high variance (for instance, by drawing a curve that passes through every single training observation) or a method with very low variance but high bias (by fitting a horizontal line to the data). The challenge lies in finding a method for which both the variance and the squared bias are low\n",
        "\n"
      ],
      "metadata": {
        "id": "IPMV8Lt9S00j"
      }
    }
  ]
}